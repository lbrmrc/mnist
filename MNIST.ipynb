{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_tXhaxZYBHIt"
   },
   "source": [
    "# Introduzione al Deep Learning con Keras e TensorFlow\n",
    "\n",
    "Credit: Daniel Moser, Xavier Snelgrove, Yash Katariya\n",
    "\n",
    "Obiettivi:\n",
    "\n",
    "Riconoscimento di cifre scritte a mano con\n",
    "\n",
    "1. rete neurale completamente connessa\n",
    "2. rete neurale convoluzionale (deep)\n",
    "\n",
    "Database: MNIST\n",
    "\n",
    "Linguaggio: Python\n",
    "\n",
    "API: Tensorflow e Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4ad89f6_BQun"
   },
   "source": [
    "### Preparazione"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "F-9Gmv4u0xf1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting np_utils\n",
      "  Using cached np_utils-0.6.0-py3-none-any.whl\n",
      "Requirement already satisfied: numpy>=1.0 in /home/marco/.local/share/virtualenvs/mnist-rkN2HkJi/lib/python3.10/site-packages (from np_utils) (1.26.4)\n",
      "Installing collected packages: np_utils\n",
      "Successfully installed np_utils-0.6.0\n",
      "Requirement already satisfied: tensorflow==2.15.0 in /home/marco/.local/share/virtualenvs/mnist-rkN2HkJi/lib/python3.10/site-packages (2.15.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /home/marco/.local/share/virtualenvs/mnist-rkN2HkJi/lib/python3.10/site-packages (from tensorflow==2.15.0) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /home/marco/.local/share/virtualenvs/mnist-rkN2HkJi/lib/python3.10/site-packages (from tensorflow==2.15.0) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in /home/marco/.local/share/virtualenvs/mnist-rkN2HkJi/lib/python3.10/site-packages (from tensorflow==2.15.0) (24.3.25)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /home/marco/.local/share/virtualenvs/mnist-rkN2HkJi/lib/python3.10/site-packages (from tensorflow==2.15.0) (0.5.4)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /home/marco/.local/share/virtualenvs/mnist-rkN2HkJi/lib/python3.10/site-packages (from tensorflow==2.15.0) (0.2.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /home/marco/.local/share/virtualenvs/mnist-rkN2HkJi/lib/python3.10/site-packages (from tensorflow==2.15.0) (3.11.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /home/marco/.local/share/virtualenvs/mnist-rkN2HkJi/lib/python3.10/site-packages (from tensorflow==2.15.0) (18.1.1)\n",
      "Requirement already satisfied: ml-dtypes~=0.2.0 in /home/marco/.local/share/virtualenvs/mnist-rkN2HkJi/lib/python3.10/site-packages (from tensorflow==2.15.0) (0.2.0)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /home/marco/.local/share/virtualenvs/mnist-rkN2HkJi/lib/python3.10/site-packages (from tensorflow==2.15.0) (1.26.4)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /home/marco/.local/share/virtualenvs/mnist-rkN2HkJi/lib/python3.10/site-packages (from tensorflow==2.15.0) (3.3.0)\n",
      "Requirement already satisfied: packaging in /home/marco/.local/share/virtualenvs/mnist-rkN2HkJi/lib/python3.10/site-packages (from tensorflow==2.15.0) (24.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /home/marco/.local/share/virtualenvs/mnist-rkN2HkJi/lib/python3.10/site-packages (from tensorflow==2.15.0) (4.25.3)\n",
      "Requirement already satisfied: setuptools in /home/marco/.local/share/virtualenvs/mnist-rkN2HkJi/lib/python3.10/site-packages (from tensorflow==2.15.0) (70.0.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /home/marco/.local/share/virtualenvs/mnist-rkN2HkJi/lib/python3.10/site-packages (from tensorflow==2.15.0) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /home/marco/.local/share/virtualenvs/mnist-rkN2HkJi/lib/python3.10/site-packages (from tensorflow==2.15.0) (2.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /home/marco/.local/share/virtualenvs/mnist-rkN2HkJi/lib/python3.10/site-packages (from tensorflow==2.15.0) (4.12.2)\n",
      "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /home/marco/.local/share/virtualenvs/mnist-rkN2HkJi/lib/python3.10/site-packages (from tensorflow==2.15.0) (1.14.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /home/marco/.local/share/virtualenvs/mnist-rkN2HkJi/lib/python3.10/site-packages (from tensorflow==2.15.0) (0.37.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /home/marco/.local/share/virtualenvs/mnist-rkN2HkJi/lib/python3.10/site-packages (from tensorflow==2.15.0) (1.64.1)\n",
      "Requirement already satisfied: tensorboard<2.16,>=2.15 in /home/marco/.local/share/virtualenvs/mnist-rkN2HkJi/lib/python3.10/site-packages (from tensorflow==2.15.0) (2.15.2)\n",
      "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /home/marco/.local/share/virtualenvs/mnist-rkN2HkJi/lib/python3.10/site-packages (from tensorflow==2.15.0) (2.15.0)\n",
      "Requirement already satisfied: keras<2.16,>=2.15.0 in /home/marco/.local/share/virtualenvs/mnist-rkN2HkJi/lib/python3.10/site-packages (from tensorflow==2.15.0) (2.15.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /home/marco/.local/share/virtualenvs/mnist-rkN2HkJi/lib/python3.10/site-packages (from astunparse>=1.6.0->tensorflow==2.15.0) (0.43.0)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /home/marco/.local/share/virtualenvs/mnist-rkN2HkJi/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15.0) (2.30.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /home/marco/.local/share/virtualenvs/mnist-rkN2HkJi/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15.0) (1.2.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/marco/.local/share/virtualenvs/mnist-rkN2HkJi/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15.0) (3.6)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /home/marco/.local/share/virtualenvs/mnist-rkN2HkJi/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15.0) (2.32.3)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /home/marco/.local/share/virtualenvs/mnist-rkN2HkJi/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15.0) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /home/marco/.local/share/virtualenvs/mnist-rkN2HkJi/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15.0) (3.0.3)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /home/marco/.local/share/virtualenvs/mnist-rkN2HkJi/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (5.3.3)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /home/marco/.local/share/virtualenvs/mnist-rkN2HkJi/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (0.4.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /home/marco/.local/share/virtualenvs/mnist-rkN2HkJi/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /home/marco/.local/share/virtualenvs/mnist-rkN2HkJi/lib/python3.10/site-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (2.0.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/marco/.local/share/virtualenvs/mnist-rkN2HkJi/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/marco/.local/share/virtualenvs/mnist-rkN2HkJi/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/marco/.local/share/virtualenvs/mnist-rkN2HkJi/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/marco/.local/share/virtualenvs/mnist-rkN2HkJi/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (2024.6.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /home/marco/.local/share/virtualenvs/mnist-rkN2HkJi/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (2.1.5)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /home/marco/.local/share/virtualenvs/mnist-rkN2HkJi/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (0.6.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /home/marco/.local/share/virtualenvs/mnist-rkN2HkJi/lib/python3.10/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (3.2.2)\n"
     ]
    }
   ],
   "source": [
    "!%pip install np_utils==0.6.0\n",
    "!%pip install tensorflow==2.15.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BNVf4yhSz_Yi"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2QQ2IL_R0NDc"
   },
   "outputs": [],
   "source": [
    "import numpy as np                   # advanced math library\n",
    "import matplotlib.pyplot as plt      # MATLAB like plotting routines\n",
    "import random                        # for generating random numbers\n",
    "\n",
    "from keras.datasets import mnist     # MNIST dataset is included in Keras\n",
    "from keras.models import Sequential  # Model type to be used\n",
    "\n",
    "from keras.layers import Dense, Dropout, Activation # Types of layers to be used in our model\n",
    "from keras.utils import to_categorical                  # NumPy related tools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dhcn7BsbCKHJ"
   },
   "source": [
    "### Caricamento dati di addestramento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = 'mnist-dataset.png' >"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sCydGMS91KLG"
   },
   "outputs": [],
   "source": [
    "# The MNIST data is split between 60,000 28 x 28 pixel training images and 10,000 28 x 28 pixel images\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "print(\"X_train shape\", X_train.shape)\n",
    "print(\"y_train shape\", y_train.shape)\n",
    "print(\"X_test shape\", X_test.shape)\n",
    "print(\"y_test shape\", y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K40RwcFYCjyX"
   },
   "source": [
    "### Rappresentazione grafica di alcune immagini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "1wpH3y4y1VHW"
   },
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = (9,9) # Make the figures a bit bigger\n",
    "\n",
    "for i in range(9):\n",
    "    plt.subplot(3,3,i+1)\n",
    "    num = random.randint(0, len(X_train))\n",
    "    plt.imshow(X_train[num], cmap='gray', interpolation='none')\n",
    "    plt.title(\"Class {}\".format(y_train[num]))\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "scZ0076ECaYX"
   },
   "source": [
    "### Rappresentazione numerica di una cifra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rLQdQ8dw1OAM"
   },
   "outputs": [],
   "source": [
    "# just a little function for pretty printing a matrix\n",
    "def matprint(mat, fmt=\"g\"):\n",
    "    col_maxes = [max([len((\"{:\"+fmt+\"}\").format(x)) for x in col]) for col in mat.T]\n",
    "    for x in mat:\n",
    "        for i, y in enumerate(x):\n",
    "            print((\"{:\"+str(col_maxes[i])+fmt+\"}\").format(y), end=\"  \")\n",
    "        print(\"\")\n",
    "\n",
    "# now print!\n",
    "matprint(X_train[num])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XRjmGcoM1njl"
   },
   "source": [
    "### Da matrice quadrata 28x28 di interi a vettore di 784 numeri reali"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9WzsZpOn1uka"
   },
   "outputs": [],
   "source": [
    "X_train = X_train.reshape(60000, 784) # reshape 60,000 28 x 28 matrices into 60,000 784-length vectors.\n",
    "X_test = X_test.reshape(10000, 784)   # reshape 10,000 28 x 28 matrices into 10,000 784-length vectors.\n",
    "\n",
    "X_train = X_train.astype('float32')   # change integers to 32-bit floating point numbers\n",
    "X_test = X_test.astype('float32')\n",
    "\n",
    "X_train /= 255                        # normalize each value for each pixel for the entire vector for each input\n",
    "X_test /= 255\n",
    "\n",
    "print(\"Training matrix shape\", X_train.shape)\n",
    "print(\"Testing matrix shape\", X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aHBuBZPqDU35"
   },
   "source": [
    "### Codifica one-hot:\n",
    "\n",
    "La classe 3 si rappresenta come [0, 0, 1, 0, 0, 0, 0, 0, 0, 0]\n",
    "\n",
    "Se la rete neurale desse come output [0, 0.03, 0.96, 0, 0, 0, 0.1, 0, 0] riconoscerebbe la cifra 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bt3Ls1x424bN"
   },
   "outputs": [],
   "source": [
    "nb_classes = 10 # number of unique digits\n",
    "\n",
    "Y_train = to_categorical(y_train, nb_classes)\n",
    "Y_test = to_categorical(y_test, nb_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-RHYj6l9GP_A"
   },
   "source": [
    "### Rete sequenziale a 3 strati, completamente connessa\n",
    "\n",
    "<img src=\"connected.png\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4UCEa-Do3EkZ"
   },
   "outputs": [],
   "source": [
    "# The Sequential model is a linear stack of layers and is very common.\n",
    "\n",
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ARszdSL-3F9K"
   },
   "outputs": [],
   "source": [
    "# The first hidden layer is a set of 512 nodes (artificial neurons).\n",
    "# Each node will receive an element from each input vector and apply some weight and bias to it.\n",
    "\n",
    "model.add(Dense(512, input_shape=(784,))) #(784,) is not a typo -- that represents a 784 length vector!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MYMT8ZLe3JT7"
   },
   "outputs": [],
   "source": [
    "# An \"activation\" is a non-linear function applied to the output of the layer above.\n",
    "# It checks the new value of the node, and decides whether that artifical neuron has fired.\n",
    "# The Rectified Linear # The first hidden layer is a set of 512 nodes (artificial neurons).\n",
    "# Each node will receive an element from each input vector and apply some weight and bias to it.\n",
    "\n",
    "model.add(Dense(512, input_shape=(784,))) #(784,) is not a typo -- that represents a 784 length vector!Unit (ReLU) converts all negative inputs to nodes in the next layer to be zero.\n",
    "# Those inputs are then not considered to be fired.\n",
    "# Positive values of a node are unchanged.\n",
    "\n",
    "model.add(Activation('relu'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = 'relu.jpg' >"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ns7HEsMo3MDJ"
   },
   "outputs": [],
   "source": [
    "# Dropout zeroes a selection of random outputs (i.e., disables their activation)\n",
    "# Dropout helps protect the model from memorizing or \"overfitting\" the training data.\n",
    "model.add(Dropout(0.2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wofcSenP3N5e"
   },
   "outputs": [],
   "source": [
    "# The second hidden layer appears identical to our first layer.\n",
    "# However, instead of each of the 512-node receiving 784-inputs from the input image data,\n",
    "# they receive 512 inputs from the output of the first 512-node layer.\n",
    "\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "h9ovgKwn3QjF"
   },
   "outputs": [],
   "source": [
    "# The final layer of 10 neurons in fully-connected to the previous 512-node layer.\n",
    "# The final layer of a FCN should be equal to the number of desired classes (10 in this case).\n",
    "model.add(Dense(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9sYEbh8R3Rp1"
   },
   "outputs": [],
   "source": [
    "# The \"softmax\" activation represents a probability distribution over K different possible outcomes.\n",
    "# Its values are all non-negative and sum to 1.\n",
    "\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "28CiciRp3SnE"
   },
   "outputs": [],
   "source": [
    "# Summarize the built model\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ee2K_weNPEDL"
   },
   "source": [
    "### Compilazione del modello\n",
    "\n",
    "Determina:\n",
    "- funzione di costo\n",
    "- ottimizzatore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wFtaqOKF3XOc"
   },
   "outputs": [],
   "source": [
    "# Let's use the Adam optimizer for learning\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QrlUhiEcPPVA"
   },
   "source": [
    "### Addestramento\n",
    "\n",
    "I parametri del modello vengono adattati dall'ottimizzatore per minimizzare la funzione di costo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Pu8l8aBV3acc"
   },
   "outputs": [],
   "source": [
    "model.fit(X_train, Y_train,\n",
    "          batch_size=128, epochs=5,\n",
    "          verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GrqL2m2lPdzm"
   },
   "source": [
    "### Valutazione sui dati di test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1LaJK8ml3d2N"
   },
   "outputs": [],
   "source": [
    "score = model.evaluate(X_test, Y_test)\n",
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RFV_Z8qoPuyH"
   },
   "source": [
    "### Ispezione dell'output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KteiTMyF4mRM"
   },
   "outputs": [],
   "source": [
    "# The predict_classes function outputs the highest probability class\n",
    "# according to the trained classifier for each input example.\n",
    "predicted_classes=np.argmax(model.predict(X_test) ,axis=1)\n",
    "\n",
    "# Check which items we got right / wrong\n",
    "correct_indices = np.nonzero(predicted_classes == y_test)[0]\n",
    "\n",
    "incorrect_indices = np.nonzero(predicted_classes != y_test)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QzV90d3w3fds"
   },
   "outputs": [],
   "source": [
    "# The predict_classes function outputs the highest probability class\n",
    "# according to the trained classifier for each input example.\n",
    "\n",
    "plt.figure()\n",
    "for i, correct in enumerate(correct_indices[:9]):\n",
    "    plt.subplot(3,3,i+1)\n",
    "    plt.imshow(X_test[correct].reshape(28,28), cmap='gray', interpolation='none')\n",
    "    plt.title(\"Predicted {}, Class {}\".format(predicted_classes[correct], y_test[correct]))\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.figure()\n",
    "for i, incorrect in enumerate(incorrect_indices[:9]):\n",
    "    plt.subplot(3,3,i+1)\n",
    "    plt.imshow(X_test[incorrect].reshape(28,28), cmap='gray', interpolation='none')\n",
    "    plt.title(\"Predicted {}, Class {}\".format(predicted_classes[incorrect], y_test[incorrect]))\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t4_nKcecP3rA"
   },
   "source": [
    "### Qual è l'effetto della dimensione del batch?\n",
    "\n",
    "Provare:\n",
    "- batch 10000\n",
    "- batch 32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cHl4WX7VQDWO"
   },
   "source": [
    "### Rete convoluzionale\n",
    "\n",
    "<img src = 'convolution.gif' >"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "v2VydWRV5FG1"
   },
   "outputs": [],
   "source": [
    "# import some additional tools\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers import Conv2D, MaxPooling2D, ZeroPadding2D, GlobalAveragePooling2D, Flatten\n",
    "from keras.layers import BatchNormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4vm0lHvS5hSU"
   },
   "outputs": [],
   "source": [
    "# Reload the MNIST data\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c_zQ8jMX5kIp"
   },
   "outputs": [],
   "source": [
    "# Again, do some formatting\n",
    "# Except we do not flatten each image into a 784-length vector because we want to perform convolutions first\n",
    "\n",
    "X_train = X_train.reshape(60000, 28, 28, 1) #add an additional dimension to represent the single-channel\n",
    "X_test = X_test.reshape(10000, 28, 28, 1)\n",
    "\n",
    "X_train = X_train.astype('float32')         # change integers to 32-bit floating point numbers\n",
    "X_test = X_test.astype('float32')\n",
    "\n",
    "X_train /= 255                              # normalize each value for each pixel for the entire vector for each input\n",
    "X_test /= 255\n",
    "\n",
    "print(\"Training matrix shape\", X_train.shape)\n",
    "print(\"Testing matrix shape\", X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9-Ev0Z_X5n8G"
   },
   "outputs": [],
   "source": [
    "# one-hot format classes\n",
    "\n",
    "nb_classes = 10 # number of unique digits\n",
    "\n",
    "Y_train = to_categorical(y_train, nb_classes)\n",
    "Y_test = to_categorical(y_test, nb_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HOT1DWg5QWYq"
   },
   "source": [
    "### Rete convoluzionale profonda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f5r4yRjp5tBl"
   },
   "outputs": [],
   "source": [
    "model = Sequential()                                 # Linear stacking of layers\n",
    "\n",
    "# Convolution Layer 1\n",
    "model.add(Conv2D(32, (3, 3), input_shape=(28,28,1))) # 32 different 3x3 kernels -- so 32 feature maps\n",
    "model.add(BatchNormalization(axis=-1))               # normalize each feature map before activation\n",
    "convLayer01 = Activation('relu')                     # activation\n",
    "model.add(convLayer01)\n",
    "\n",
    "# Convolution Layer 2\n",
    "model.add(Conv2D(32, (3, 3)))                        # 32 different 3x3 kernels -- so 32 feature maps\n",
    "model.add(BatchNormalization(axis=-1))               # normalize each feature map before activation\n",
    "model.add(Activation('relu'))                        # activation\n",
    "convLayer02 = MaxPooling2D(pool_size=(2,2))          # Pool the max values over a 2x2 kernel\n",
    "model.add(convLayer02)\n",
    "\n",
    "# Convolution Layer 3\n",
    "model.add(Conv2D(64,(3, 3)))                         # 64 different 3x3 kernels -- so 64 feature maps\n",
    "model.add(BatchNormalization(axis=-1))               # normalize each feature map before activation\n",
    "convLayer03 = Activation('relu')                     # activation\n",
    "model.add(convLayer03)\n",
    "\n",
    "# Convolution Layer 4\n",
    "model.add(Conv2D(64, (3, 3)))                        # 64 different 3x3 kernels -- so 64 feature maps\n",
    "model.add(BatchNormalization(axis=-1))               # normalize each feature map before activation\n",
    "model.add(Activation('relu'))                        # activation\n",
    "convLayer04 = MaxPooling2D(pool_size=(2,2))          # Pool the max values over a 2x2 kernel\n",
    "model.add(convLayer04)\n",
    "model.add(Flatten())                                 # Flatten final 4x4x64 output matrix into a 1024-length vector\n",
    "\n",
    "# Fully Connected Layer 5\n",
    "model.add(Dense(512))                                # 512 FCN nodes\n",
    "model.add(BatchNormalization())                      # normalization\n",
    "model.add(Activation('relu'))                        # activation\n",
    "\n",
    "# Fully Connected Layer 6\n",
    "model.add(Dropout(0.2))                              # 20% dropout of randomly selected nodes\n",
    "model.add(Dense(10))                                 # final 10 FCN nodes\n",
    "model.add(Activation('softmax'))                     # softmax activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "g9yOBOq45wK6"
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5-QrMEl2QckQ"
   },
   "source": [
    "## Compilazione"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uc4GPiIW5ytR"
   },
   "outputs": [],
   "source": [
    "# we'll use the same optimizer\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AnWoykPx50wQ"
   },
   "outputs": [],
   "source": [
    "# data augmentation prevents overfitting by slightly changing the data randomly\n",
    "# Keras has a great built-in feature to do automatic augmentation\n",
    "\n",
    "gen = ImageDataGenerator(rotation_range=8, width_shift_range=0.08, shear_range=0.3,\n",
    "                         height_shift_range=0.08, zoom_range=0.08)\n",
    "\n",
    "test_gen = ImageDataGenerator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KoLUCjAn52hv"
   },
   "outputs": [],
   "source": [
    "# We can then feed our augmented data in batches\n",
    "# Besides loss function considerations as before, this method actually results in significant memory savings\n",
    "# because we are actually LOADING the data into the network in batches before processing each batch\n",
    "\n",
    "# Before the data was all loaded into memory, but then processed in batches.\n",
    "\n",
    "train_generator = gen.flow(X_train, Y_train, batch_size=128)\n",
    "test_generator = test_gen.flow(X_test, Y_test, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "83KH_25O54Nx"
   },
   "outputs": [],
   "source": [
    "# We can now train our model which is fed data by our batch loader\n",
    "# Steps per epoch should always be total size of the set divided by the batch size\n",
    "\n",
    "# SIGNIFICANT MEMORY SAVINGS (important for larger, deeper networks)\n",
    "\n",
    "model.fit_generator(train_generator, steps_per_epoch=60000//128, epochs=1, verbose=1,\n",
    "                    validation_data=test_generator, validation_steps=10000//128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ti8BUV5D57Qk"
   },
   "outputs": [],
   "source": [
    "score = model.evaluate(X_test, Y_test)\n",
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nEF3ohlaH_nW"
   },
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "\n",
    "# choose any image to want by specifying the index\n",
    "img = X_test[3]\n",
    "img = np.expand_dims(img, axis=0) # Keras requires the image to be in 4D, so we add an extra dimension to it.\n",
    "\n",
    "# Not important to understand how this function work -- It just plots a convolution layer\n",
    "\n",
    "# Function to visualize feature maps\n",
    "def visualize(layer):\n",
    "    # Define a Keras function to get the output of the layer\n",
    "    func = K.function([model.input], [layer.output])\n",
    "\n",
    "    # Get the feature maps\n",
    "    feature_maps = func([img])[0]\n",
    "\n",
    "    # Remove the batch dimension\n",
    "    feature_maps = np.squeeze(feature_maps, axis=0)\n",
    "\n",
    "    print('Shape of feature maps:', feature_maps.shape)\n",
    "\n",
    "    # Number of feature maps\n",
    "    num_feature_maps = feature_maps.shape[-1]\n",
    "\n",
    "    # Calculate grid size\n",
    "    grid_size = int(np.ceil(np.sqrt(num_feature_maps)))\n",
    "\n",
    "    # Plot the feature maps\n",
    "    fig, axes = plt.subplots(grid_size, grid_size, figsize=(15, 15))\n",
    "    axes = axes.flatten()\n",
    "\n",
    "    for i in range(num_feature_maps):\n",
    "        ax = axes[i]\n",
    "        ax.imshow(feature_maps[:, :, i], cmap='viridis')\n",
    "        ax.axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wYHzcEW46Mcw"
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.imshow(X_test[3].reshape(28,28), cmap='gray', interpolation='none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KF7XNXrt6NvL"
   },
   "outputs": [],
   "source": [
    "visualize(convLayer01) # visualize first set of feature maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HYLiavZt6PCz"
   },
   "outputs": [],
   "source": [
    "visualize(convLayer02) # visualize second set of feature maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6h-bOOGq6QOs"
   },
   "outputs": [],
   "source": [
    "visualize(convLayer03)# visualize third set of feature maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pvf-sdUi6RZX"
   },
   "outputs": [],
   "source": [
    "visualize(convLayer04)# visualize fourth set of feature maps"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "mnist-rkN2HkJi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
