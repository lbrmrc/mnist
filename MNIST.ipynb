{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Introduzione al Deep Learning con Keras e TensorFlow\n","\n","Credit: Daniel Moser, Xavier Snelgrove, Yash Katariya\n","\n","Obiettivi:\n","\n","Riconoscimento di cifre scritte a mano con\n","\n","1. rete neurale completamente connessa\n","2. rete neurale convoluzionale (deep)\n","\n","Database: MNIST\n","\n","Linguaggio: Python\n","\n","API: Tensorflow e Keras"],"metadata":{"id":"_tXhaxZYBHIt"}},{"cell_type":"markdown","source":["### Preparazione"],"metadata":{"id":"4ad89f6_BQun"}},{"cell_type":"code","source":["!pip install np_utils"],"metadata":{"id":"F-9Gmv4u0xf1"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BNVf4yhSz_Yi"},"outputs":[],"source":["%matplotlib inline"]},{"cell_type":"code","source":["import numpy as np                   # advanced math library\n","import matplotlib.pyplot as plt      # MATLAB like plotting routines\n","import random                        # for generating random numbers\n","\n","from keras.datasets import mnist     # MNIST dataset is included in Keras\n","from keras.models import Sequential  # Model type to be used\n","\n","from keras.layers import Dense, Dropout, Activation # Types of layers to be used in our model\n","from keras.utils import to_categorical                  # NumPy related tools"],"metadata":{"id":"2QQ2IL_R0NDc"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Caricamento dati di addestramento"],"metadata":{"id":"dhcn7BsbCKHJ"}},{"cell_type":"code","source":[],"metadata":{"id":"KiNVj093CO2K"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# The MNIST data is split between 60,000 28 x 28 pixel training images and 10,000 28 x 28 pixel images\n","(X_train, y_train), (X_test, y_test) = mnist.load_data()\n","\n","print(\"X_train shape\", X_train.shape)\n","print(\"y_train shape\", y_train.shape)\n","print(\"X_test shape\", X_test.shape)\n","print(\"y_test shape\", y_test.shape)"],"metadata":{"id":"sCydGMS91KLG"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Rappresentazione grafica di alcune immagini"],"metadata":{"id":"K40RwcFYCjyX"}},{"cell_type":"code","source":["plt.rcParams['figure.figsize'] = (9,9) # Make the figures a bit bigger\n","\n","for i in range(9):\n","    plt.subplot(3,3,i+1)\n","    num = random.randint(0, len(X_train))\n","    plt.imshow(X_train[num], cmap='gray', interpolation='none')\n","    plt.title(\"Class {}\".format(y_train[num]))\n","\n","plt.tight_layout()"],"metadata":{"collapsed":true,"id":"1wpH3y4y1VHW"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Rappresentazione numerica di una cifra"],"metadata":{"id":"scZ0076ECaYX"}},{"cell_type":"code","source":["# just a little function for pretty printing a matrix\n","def matprint(mat, fmt=\"g\"):\n","    col_maxes = [max([len((\"{:\"+fmt+\"}\").format(x)) for x in col]) for col in mat.T]\n","    for x in mat:\n","        for i, y in enumerate(x):\n","            print((\"{:\"+str(col_maxes[i])+fmt+\"}\").format(y), end=\"  \")\n","        print(\"\")\n","\n","# now print!\n","matprint(X_train[num])"],"metadata":{"id":"rLQdQ8dw1OAM"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Da matrice quadrata 28x28 di interi a vettore di 784 numeri reali"],"metadata":{"id":"XRjmGcoM1njl"}},{"cell_type":"code","source":["X_train = X_train.reshape(60000, 784) # reshape 60,000 28 x 28 matrices into 60,000 784-length vectors.\n","X_test = X_test.reshape(10000, 784)   # reshape 10,000 28 x 28 matrices into 10,000 784-length vectors.\n","\n","X_train = X_train.astype('float32')   # change integers to 32-bit floating point numbers\n","X_test = X_test.astype('float32')\n","\n","X_train /= 255                        # normalize each value for each pixel for the entire vector for each input\n","X_test /= 255\n","\n","print(\"Training matrix shape\", X_train.shape)\n","print(\"Testing matrix shape\", X_test.shape)"],"metadata":{"id":"9WzsZpOn1uka"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Codifica one-hot:\n","\n","La classe 3 si rappresenta come [0, 0, 1, 0, 0, 0, 0, 0, 0, 0]\n","\n","Se la rete neurale desse come output [0, 0.03, 0.96, 0, 0, 0, 0.1, 0, 0] riconoscerebbe la cifra 3"],"metadata":{"id":"aHBuBZPqDU35"}},{"cell_type":"code","source":["nb_classes = 10 # number of unique digits\n","\n","Y_train = to_categorical(y_train, nb_classes)\n","Y_test = to_categorical(y_test, nb_classes)"],"metadata":{"id":"bt3Ls1x424bN"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Rete sequenziale a 3 strati, completamente connessa"],"metadata":{"id":"-RHYj6l9GP_A"}},{"cell_type":"code","source":["# The Sequential model is a linear stack of layers and is very common.\n","\n","model = Sequential()"],"metadata":{"id":"4UCEa-Do3EkZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# The first hidden layer is a set of 512 nodes (artificial neurons).\n","# Each node will receive an element from each input vector and apply some weight and bias to it.\n","\n","model.add(Dense(512, input_shape=(784,))) #(784,) is not a typo -- that represents a 784 length vector!"],"metadata":{"id":"ARszdSL-3F9K"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# An \"activation\" is a non-linear function applied to the output of the layer above.\n","# It checks the new value of the node, and decides whether that artifical neuron has fired.\n","# The Rectified Linear # The first hidden layer is a set of 512 nodes (artificial neurons).\n","# Each node will receive an element from each input vector and apply some weight and bias to it.\n","\n","model.add(Dense(512, input_shape=(784,))) #(784,) is not a typo -- that represents a 784 length vector!Unit (ReLU) converts all negative inputs to nodes in the next layer to be zero.\n","# Those inputs are then not considered to be fired.\n","# Positive values of a node are unchanged.\n","\n","model.add(Activation('relu'))"],"metadata":{"id":"MYMT8ZLe3JT7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Dropout zeroes a selection of random outputs (i.e., disables their activation)\n","# Dropout helps protect the model from memorizing or \"overfitting\" the training data.\n","model.add(Dropout(0.2))"],"metadata":{"id":"ns7HEsMo3MDJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# The second hidden layer appears identical to our first layer.\n","# However, instead of each of the 512-node receiving 784-inputs from the input image data,\n","# they receive 512 inputs from the output of the first 512-node layer.\n","\n","model.add(Dense(512))\n","model.add(Activation('relu'))\n","model.add(Dropout(0.2))"],"metadata":{"id":"wofcSenP3N5e"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# The final layer of 10 neurons in fully-connected to the previous 512-node layer.\n","# The final layer of a FCN should be equal to the number of desired classes (10 in this case).\n","model.add(Dense(10))"],"metadata":{"id":"h9ovgKwn3QjF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# The \"softmax\" activation represents a probability distribution over K different possible outcomes.\n","# Its values are all non-negative and sum to 1.\n","\n","model.add(Activation('softmax'))"],"metadata":{"id":"9sYEbh8R3Rp1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Summarize the built model\n","\n","model.summary()"],"metadata":{"id":"28CiciRp3SnE"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Compilazione del modello\n","\n","Determina:\n","- funzione di costo\n","- ottimizzatore"],"metadata":{"id":"ee2K_weNPEDL"}},{"cell_type":"code","source":["# Let's use the Adam optimizer for learning\n","model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"],"metadata":{"id":"wFtaqOKF3XOc"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Addestramento\n","\n","I parametri del modello vengono adattati dall'ottimizzatore per minimizzare la funzione di costo"],"metadata":{"id":"QrlUhiEcPPVA"}},{"cell_type":"code","source":["model.fit(X_train, Y_train,\n","          batch_size=128, epochs=5,\n","          verbose=1)"],"metadata":{"id":"Pu8l8aBV3acc"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Valutazione sui dati di test"],"metadata":{"id":"GrqL2m2lPdzm"}},{"cell_type":"code","source":["score = model.evaluate(X_test, Y_test)\n","print('Test score:', score[0])\n","print('Test accuracy:', score[1])"],"metadata":{"id":"1LaJK8ml3d2N"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Ispezione dell'output"],"metadata":{"id":"RFV_Z8qoPuyH"}},{"cell_type":"code","source":["# The predict_classes function outputs the highest probability class\n","# according to the trained classifier for each input example.\n","predicted_classes=np.argmax(model.predict(X_test) ,axis=1)\n","\n","# Check which items we got right / wrong\n","correct_indices = np.nonzero(predicted_classes == y_test)[0]\n","\n","incorrect_indices = np.nonzero(predicted_classes != y_test)[0]"],"metadata":{"id":"KteiTMyF4mRM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# The predict_classes function outputs the highest probability class\n","# according to the trained classifier for each input example.\n","\n","plt.figure()\n","for i, correct in enumerate(correct_indices[:9]):\n","    plt.subplot(3,3,i+1)\n","    plt.imshow(X_test[correct].reshape(28,28), cmap='gray', interpolation='none')\n","    plt.title(\"Predicted {}, Class {}\".format(predicted_classes[correct], y_test[correct]))\n","\n","plt.tight_layout()\n","\n","plt.figure()\n","for i, incorrect in enumerate(incorrect_indices[:9]):\n","    plt.subplot(3,3,i+1)\n","    plt.imshow(X_test[incorrect].reshape(28,28), cmap='gray', interpolation='none')\n","    plt.title(\"Predicted {}, Class {}\".format(predicted_classes[incorrect], y_test[incorrect]))\n","\n","plt.tight_layout()"],"metadata":{"id":"QzV90d3w3fds"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Qual è l'effetto della dimensione del batch?\n","\n","Provare:\n","- batch 10000\n","- batch 32"],"metadata":{"id":"t4_nKcecP3rA"}},{"cell_type":"markdown","source":["### Rete convoluzionale"],"metadata":{"id":"cHl4WX7VQDWO"}},{"cell_type":"code","source":["# import some additional tools\n","\n","from keras.preprocessing.image import ImageDataGenerator\n","from keras.layers import Conv2D, MaxPooling2D, ZeroPadding2D, GlobalAveragePooling2D, Flatten\n","from keras.layers import BatchNormalization"],"metadata":{"id":"v2VydWRV5FG1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Reload the MNIST data\n","(X_train, y_train), (X_test, y_test) = mnist.load_data()"],"metadata":{"id":"4vm0lHvS5hSU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Again, do some formatting\n","# Except we do not flatten each image into a 784-length vector because we want to perform convolutions first\n","\n","X_train = X_train.reshape(60000, 28, 28, 1) #add an additional dimension to represent the single-channel\n","X_test = X_test.reshape(10000, 28, 28, 1)\n","\n","X_train = X_train.astype('float32')         # change integers to 32-bit floating point numbers\n","X_test = X_test.astype('float32')\n","\n","X_train /= 255                              # normalize each value for each pixel for the entire vector for each input\n","X_test /= 255\n","\n","print(\"Training matrix shape\", X_train.shape)\n","print(\"Testing matrix shape\", X_test.shape)"],"metadata":{"id":"c_zQ8jMX5kIp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# one-hot format classes\n","\n","nb_classes = 10 # number of unique digits\n","\n","Y_train = to_categorical(y_train, nb_classes)\n","Y_test = to_categorical(y_test, nb_classes)"],"metadata":{"id":"9-Ev0Z_X5n8G"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Rete convoluzionale profonda"],"metadata":{"id":"HOT1DWg5QWYq"}},{"cell_type":"code","source":["model = Sequential()                                 # Linear stacking of layers\n","\n","# Convolution Layer 1\n","model.add(Conv2D(32, (3, 3), input_shape=(28,28,1))) # 32 different 3x3 kernels -- so 32 feature maps\n","model.add(BatchNormalization(axis=-1))               # normalize each feature map before activation\n","convLayer01 = Activation('relu')                     # activation\n","model.add(convLayer01)\n","\n","# Convolution Layer 2\n","model.add(Conv2D(32, (3, 3)))                        # 32 different 3x3 kernels -- so 32 feature maps\n","model.add(BatchNormalization(axis=-1))               # normalize each feature map before activation\n","model.add(Activation('relu'))                        # activation\n","convLayer02 = MaxPooling2D(pool_size=(2,2))          # Pool the max values over a 2x2 kernel\n","model.add(convLayer02)\n","\n","# Convolution Layer 3\n","model.add(Conv2D(64,(3, 3)))                         # 64 different 3x3 kernels -- so 64 feature maps\n","model.add(BatchNormalization(axis=-1))               # normalize each feature map before activation\n","convLayer03 = Activation('relu')                     # activation\n","model.add(convLayer03)\n","\n","# Convolution Layer 4\n","model.add(Conv2D(64, (3, 3)))                        # 64 different 3x3 kernels -- so 64 feature maps\n","model.add(BatchNormalization(axis=-1))               # normalize each feature map before activation\n","model.add(Activation('relu'))                        # activation\n","convLayer04 = MaxPooling2D(pool_size=(2,2))          # Pool the max values over a 2x2 kernel\n","model.add(convLayer04)\n","model.add(Flatten())                                 # Flatten final 4x4x64 output matrix into a 1024-length vector\n","\n","# Fully Connected Layer 5\n","model.add(Dense(512))                                # 512 FCN nodes\n","model.add(BatchNormalization())                      # normalization\n","model.add(Activation('relu'))                        # activation\n","\n","# Fully Connected Layer 6\n","model.add(Dropout(0.2))                              # 20% dropout of randomly selected nodes\n","model.add(Dense(10))                                 # final 10 FCN nodes\n","model.add(Activation('softmax'))                     # softmax activation"],"metadata":{"id":"f5r4yRjp5tBl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model.summary()"],"metadata":{"id":"g9yOBOq45wK6"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Compilazione"],"metadata":{"id":"5-QrMEl2QckQ"}},{"cell_type":"code","source":["# we'll use the same optimizer\n","\n","model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"],"metadata":{"id":"uc4GPiIW5ytR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# data augmentation prevents overfitting by slightly changing the data randomly\n","# Keras has a great built-in feature to do automatic augmentation\n","\n","gen = ImageDataGenerator(rotation_range=8, width_shift_range=0.08, shear_range=0.3,\n","                         height_shift_range=0.08, zoom_range=0.08)\n","\n","test_gen = ImageDataGenerator()"],"metadata":{"id":"AnWoykPx50wQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# We can then feed our augmented data in batches\n","# Besides loss function considerations as before, this method actually results in significant memory savings\n","# because we are actually LOADING the data into the network in batches before processing each batch\n","\n","# Before the data was all loaded into memory, but then processed in batches.\n","\n","train_generator = gen.flow(X_train, Y_train, batch_size=128)\n","test_generator = test_gen.flow(X_test, Y_test, batch_size=128)"],"metadata":{"id":"KoLUCjAn52hv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# We can now train our model which is fed data by our batch loader\n","# Steps per epoch should always be total size of the set divided by the batch size\n","\n","# SIGNIFICANT MEMORY SAVINGS (important for larger, deeper networks)\n","\n","model.fit_generator(train_generator, steps_per_epoch=60000//128, epochs=1, verbose=1,\n","                    validation_data=test_generator, validation_steps=10000//128)"],"metadata":{"id":"83KH_25O54Nx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["score = model.evaluate(X_test, Y_test)\n","print('Test score:', score[0])\n","print('Test accuracy:', score[1])"],"metadata":{"id":"Ti8BUV5D57Qk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from keras import backend as K\n","\n","# choose any image to want by specifying the index\n","img = X_test[3]\n","img = np.expand_dims(img, axis=0) # Keras requires the image to be in 4D, so we add an extra dimension to it.\n","\n","# Not important to understand how this function work -- It just plots a convolution layer\n","\n","# Function to visualize feature maps\n","def visualize(layer):\n","    # Define a Keras function to get the output of the layer\n","    func = K.function([model.input], [layer.output])\n","\n","    # Get the feature maps\n","    feature_maps = func([img])[0]\n","\n","    # Remove the batch dimension\n","    feature_maps = np.squeeze(feature_maps, axis=0)\n","\n","    print('Shape of feature maps:', feature_maps.shape)\n","\n","    # Number of feature maps\n","    num_feature_maps = feature_maps.shape[-1]\n","\n","    # Calculate grid size\n","    grid_size = int(np.ceil(np.sqrt(num_feature_maps)))\n","\n","    # Plot the feature maps\n","    fig, axes = plt.subplots(grid_size, grid_size, figsize=(15, 15))\n","    axes = axes.flatten()\n","\n","    for i in range(num_feature_maps):\n","        ax = axes[i]\n","        ax.imshow(feature_maps[:, :, i], cmap='viridis')\n","        ax.axis('off')\n","\n","    plt.tight_layout()\n","    plt.show()\n"],"metadata":{"id":"nEF3ohlaH_nW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plt.figure()\n","plt.imshow(X_test[3].reshape(28,28), cmap='gray', interpolation='none')"],"metadata":{"id":"wYHzcEW46Mcw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["visualize(convLayer01) # visualize first set of feature maps"],"metadata":{"id":"KF7XNXrt6NvL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["visualize(convLayer02) # visualize second set of feature maps"],"metadata":{"id":"HYLiavZt6PCz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["visualize(convLayer03)# visualize third set of feature maps"],"metadata":{"id":"6h-bOOGq6QOs"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["visualize(convLayer04)# visualize fourth set of feature maps"],"metadata":{"id":"pvf-sdUi6RZX"},"execution_count":null,"outputs":[]}]}